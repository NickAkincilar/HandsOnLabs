{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "libs",
    "collapsed": false
   },
   "source": "#  Copyright (c) 2023 Snowflake Computing Inc. All rights reserved.\n\n# Import python packages & establish session\nimport streamlit as st # Import python packages\nimport pandas as pd\nfrom PyPDF2 import PdfFileReader\nfrom snowflake.snowpark.files import SnowflakeFile\nfrom io import BytesIO\nfrom snowflake.snowpark.types import StringType, StructField, StructType\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\nprint('Session Created!')\n#test23\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "773e2ab6-8890-4e09-80cc-dec1d9d3a3e0",
   "metadata": {
    "name": "Details",
    "collapsed": false
   },
   "source": "RAG Made Easy w/ Snowflake Cortex\n========\n\nCreating an end-to-end Retrieval Augmented Generation process (or RAG) directly in Snowflake.\n1) Extract full text from PDF files using Snowpark.\n2) Chunk those documents using Langchain in Snowpark.\n3) Use Cortex to create embeddings of those chunks.\n4) Use Vector Similarity to show the most similar chunk when prompting an LLM."
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "List_files",
    "collapsed": false
   },
   "source": "-- Optional set up: Place your MD files in a stage for extraction\n--ls @INTERNALSTORAGE;\n\nselect * from directory(@internalstorage);",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "Extract_Text_img",
    "collapsed": false,
    "codeCollapsed": true
   },
   "source": "st.image( \"https://raw.githubusercontent.com/NickAkincilar/DemoContent/master/Extract_Text.png\" )",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "514bc9f5-d637-48f0-9f53-8fa8cd1ed04e",
   "metadata": {
    "language": "python",
    "name": "read_pdf_function",
    "collapsed": false
   },
   "outputs": [],
   "source": "#Create a Snowpark based function to extract text from PDFs\n__name__ = '__main__'\ndef readpdf(file_path):\n    whole_text = \"\"\n    with SnowflakeFile.open(file_path, 'rb') as file:\n        f = BytesIO(file.readall())\n        pdf_reader = PdfFileReader(f)\n        whole_text = \"\"\n        for page in pdf_reader.pages:\n            whole_text += page.extract_text()\n    return whole_text",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e504c31f-954d-41d5-9acf-61e6bc8b95a4",
   "metadata": {
    "language": "python",
    "name": "UDF_register",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Register the UDF. \n#Optional : Convert the cell to markdown to prevent rerunning later.\nsession.udf.register(\n    func = readpdf\n  , return_type = StringType()\n  , input_types = [StringType()]\n  , is_permanent = True\n  , name = 'SNOWPARK_PDF'\n  , replace = True\n  , packages=['snowflake-snowpark-python','pypdf2']\n  , stage_location = 'DOC_AI_DB.LLM_DEMO.MY_UDF_STAGE'\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "64d1700b-82ce-4f0d-9e30-2cafaa4f298a",
   "metadata": {
    "language": "python",
    "name": "pdf_text_img",
    "collapsed": false,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "st.image( \"https://raw.githubusercontent.com/NickAkincilar/DemoContent/master/Extract_Text.png\" )",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2e09c82d-b87d-4ada-b529-d5bd80813d32",
   "metadata": {
    "language": "sql",
    "name": "RAW_TEXT",
    "collapsed": false
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE RAW_TEXT AS\nSELECT\n    relative_path\n    , file_url\n    , snowpark_pdf(build_scoped_file_url(@internalstorage, relative_path)) as raw_text\nfrom directory(@internalstorage);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a10bb1af-d18d-4e23-aadf-383380d60ac6",
   "metadata": {
    "language": "sql",
    "name": "View_Raw_Text",
    "collapsed": false
   },
   "outputs": [],
   "source": "select * from raw_text;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a0c722f4-26a7-4b55-81c1-883366a51ea2",
   "metadata": {
    "language": "python",
    "name": "WebScrape_img",
    "collapsed": false,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "st.image( \"https://raw.githubusercontent.com/NickAkincilar/DemoContent/master/Extract_web.png\" )",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f48f8e73-b4f0-4101-af83-6585f64a7915",
   "metadata": {
    "language": "sql",
    "name": "WebScrape_SQL",
    "collapsed": false
   },
   "outputs": [],
   "source": "insert into RAW_TEXT \nselect \n'NBA', \n'privacy-policy', \ndeletethis.public.webscrape_via_python('https://www.nba.com/privacy-policy')\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "85900996-413e-4639-a2bc-6e1f89dbffed",
   "metadata": {
    "language": "sql",
    "name": "WebScrape_View",
    "collapsed": false
   },
   "outputs": [],
   "source": "SELECT\n*\nFROM RAW_TEXT\nwhere relative_path ilike '%nba%'",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8aac377c-30f8-4efd-8fca-eb1c684bfe9d",
   "metadata": {
    "language": "sql",
    "name": "Good_LLM_Question",
    "collapsed": false
   },
   "outputs": [],
   "source": "--Optional : This will fail due to tokens exceeding limit, which means we need to chunk!\nSELECT\nSNOWFLAKE.CORTEX.COMPLETE('llama2-70b-chat','What year Snowflake Inc. was founded?') as Answer",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3f6f6743-b242-4188-8f0a-dfd51c4d52d2",
   "metadata": {
    "language": "sql",
    "name": "Bad_LLM_Question",
    "collapsed": false
   },
   "outputs": [],
   "source": "--Optional : This will fail due to tokens exceeding limit, which means we need to chunk!\nSELECT\nSNOWFLAKE.CORTEX.COMPLETE('llama2-70b-chat','summarise the following text:' || raw_text) \nFROM\nRAW_TEXT\nLIMIT 1;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5d6e03c9-ed77-4743-8da0-d2549e21d510",
   "metadata": {
    "name": "Chunking_Note",
    "collapsed": false
   },
   "source": "A note on chunking\n-----\nChunking is the process of splitting a large body of text into smaller 'chunks' whilst attempting to keep as much relevant information as possible. Make the chunks too small and you run the risk of removing key information that the model requires to answer the question. Too large and it may be harder to retreive the correct body of text from the vector search - or spend tokens excessively.\n\nThere are many strategies towards chunking. Eg - pass the most relevant, top n relevant chunks, or pass the most relevent chunk + the chunk either side of that one. Play around and see what works for your use case!\n"
  },
  {
   "cell_type": "code",
   "id": "00f5da62-56e2-429c-aa22-240c6a20fc47",
   "metadata": {
    "language": "python",
    "name": "Chunking_Img",
    "collapsed": false,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "st.image( \"https://raw.githubusercontent.com/NickAkincilar/DemoContent/master/Chunk.text.png\" )",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "adb01d94-643b-4ffd-85cd-b56a39546bf1",
   "metadata": {
    "language": "python",
    "name": "Chunker_UDTF",
    "collapsed": false
   },
   "outputs": [],
   "source": "#A class for chunking text and returning a table via UDTF\n__name__ = '__main__'\nclass text_chunker:\n\n    def process(self,text):        \n        text_raw=[]\n        text_raw.append(text) \n        \n        text_splitter = RecursiveCharacterTextSplitter(\n            separators = [\"\\n\"], # Define an appropriate separator. New line is good typically!\n            chunk_size = 1000, #Adjust this as you see fit\n            chunk_overlap  = 50, #This let's text have some form of overlap. Useful for keeping chunks contextual\n            length_function = len,\n            add_start_index = True #Optional but useful if you'd like to feed the chunk before/after\n        )\n    \n        chunks = text_splitter.create_documents(text_raw)\n        df = pd.DataFrame(chunks, columns=['chunks','meta'])\n        \n        yield from df.itertuples(index=False, name=None)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4f473258-d35d-43b3-8e32-33ea30903f53",
   "metadata": {
    "language": "python",
    "name": "Chunker_Register_UDTF",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Register the UDTF - set the stage location\n\nschema = StructType([\n     StructField(\"chunk\", StringType()),\n    StructField(\"meta\", StringType()),\n ])\n\nsession.udtf.register( \n    handler = text_chunker,\n    output_schema= schema, \n    input_types = [StringType()] , \n    is_permanent = True , \n    name = 'CHUNK_TEXT' , \n    replace = True , \n    packages=['pandas','langchain'], stage_location = 'DOC_AI_DB.LLM_DEMO.MY_UDF_STAGE' )",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "002c5d3c-a285-41f0-a33d-f7be280577a7",
   "metadata": {
    "language": "sql",
    "name": "Chunk_Table_Create",
    "collapsed": false
   },
   "outputs": [],
   "source": "--Create the chunked version of the table\nCREATE OR REPLACE TABLE CHUNK_TEXT AS\nSELECT\n        relative_path,\n        func.*\n    FROM raw_text AS raw,\n         TABLE(chunk_text(raw_text)) as func;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f6a7abad-2233-44d5-9ade-199115d19b79",
   "metadata": {
    "language": "sql",
    "name": "Chuck_Table_view",
    "collapsed": false
   },
   "outputs": [],
   "source": "SELECT * FROM CHUNK_TEXT limit 10;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d99054bd-b936-4562-b389-48ff2004fd00",
   "metadata": {
    "language": "python",
    "name": "Embedding_img",
    "collapsed": false,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "st.image( \"https://raw.githubusercontent.com/NickAkincilar/DemoContent/master/Embed_text4.png\" )",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e660d969-e69c-4fce-b904-73e35d9915bd",
   "metadata": {
    "language": "sql",
    "name": "VectorStore_Create",
    "collapsed": false
   },
   "outputs": [],
   "source": "--Convert your chunks to embeddings\nCREATE OR REPLACE TABLE VECTOR_STORE AS\nSELECT\nRELATIVE_PATH as DOC_NAME,\nCHUNK AS CHUNK,\nsnowflake.cortex.embed_text('e5-base-v2', chunk) as chunk_embedding\nFROM CHUNK_TEXT;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9ed8383f-78f5-43b1-b628-cf58c16f7220",
   "metadata": {
    "language": "python",
    "name": "VectorStore_img",
    "collapsed": false,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "st.image( \"https://raw.githubusercontent.com/NickAkincilar/DemoContent/master/Search_text.png\" )",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4e4a8ff3-0f79-478e-8562-1729fcd2fc4a",
   "metadata": {
    "language": "sql",
    "name": "VectorStore_Distance",
    "collapsed": false
   },
   "outputs": [],
   "source": "--Vector distance allows use to find the most similar chunk to a question\nSELECT DOC_NAME, CHUNK from DOC_AI_DB.DOC_AI_SCHEMA.VECTOR_STORE \n            ORDER BY VECTOR_L2_DISTANCE(\n            snowflake.cortex.embed_text('e5-base-v2', 'what is results cache?')\n            , CHUNK_EMBEDDING) limit 3\n        ;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "40e4cdaf-05ae-49f5-b0c1-a4dc51727531",
   "metadata": {
    "language": "python",
    "name": "LLM_img",
    "collapsed": false,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "st.image( \"https://raw.githubusercontent.com/NickAkincilar/DemoContent/master/Complete_LLM1.png\" )",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9406a087-bbc5-4c49-98e5-8abe639625c4",
   "metadata": {
    "language": "sql",
    "name": "RAG_Query",
    "collapsed": false
   },
   "outputs": [],
   "source": "\n--Pass the chunk we need along with the prompt to get a better structured answer from the LLM\nSELECT snowflake.cortex.complete(\n    'llama2-70b-chat', CONCAT( \n    'Answer the question based on the context. Be concise.','Context: ',\n        (\n            SELECT chunk FROM DOC_AI_DB.DOC_AI_SCHEMA.VECTOR_STORE\n            ORDER BY vector_l2_distance(\n            snowflake.cortex.embed_text('e5-base-v2', \n            'how to disable traction control?'\n            ), chunk_embedding\n            ) LIMIT 1\n        ),\n        'Question: ', \n        'how to disable traction control?',\n        'Answer: '\n    )\n) as response;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "07397dd1-e6c6-4caf-a8df-7bf41fd80984",
   "metadata": {
    "language": "python",
    "name": "SQL_to_Dataframes",
    "collapsed": false
   },
   "outputs": [],
   "source": "df = cells.RAG_Query.to_df()\ndf.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c08aab9d-d9a0-438b-ae8a-75bfcb2a2816",
   "metadata": {
    "language": "python",
    "name": "RAG_Img",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "\nst.image( \"https://media.licdn.com/dms/image/D4E12AQFiylBcFOLdmw/article-inline_image-shrink_1500_2232/0/1716123014576?e=1721865600&v=beta&t=jNmSy7km8OJXai4quTdigYofYhY6Y8oJmbXnh2zdOU0\" )",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5961d274-5cb4-4a1f-8f6a-26c1e724f123",
   "metadata": {
    "language": "python",
    "name": "RAG_App",
    "collapsed": false
   },
   "outputs": [],
   "source": "\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session() # Get the current credentials\n\nst.title(\"Ask Your Data Anything :snowflake:\")\nst.write(\"\"\"Built using end-to-end RAG in Snowflake with Cortex functions.\"\"\")\n\nmodel = st.selectbox('Select your model:',('snowflake-arctic', 'mistral-large','llama2-70b-chat','mixtral-8x7b','gemma-7b','mistral-7b'))\n\nprompt = st.text_input(\"Enter prompt\", placeholder=\"How much does the car weigh?\", label_visibility=\"collapsed\")\n\nquest_q = f'''\nselect snowflake.cortex.complete(\n    '{model}', \n    concat( \n        'Answer the question based on the context. Be consise','Context: ',\n        (\n            select chunk from DOC_AI_DB.DOC_AI_SCHEMA.VECTOR_STORE \n            order by vector_l2_distance(\n            snowflake.cortex.embed_text('e5-base-v2', \n            '{prompt}'\n            ), chunk_embedding\n            ) limit 1\n        ),\n        'Question: ', \n        '{prompt}',\n        'Answer: '\n    )\n) as response;\n'''\n\nif prompt:\n    df_query = session.sql(quest_q).to_pandas()\n    st.write(df_query['RESPONSE'][0])",
   "execution_count": null
  }
 ]
}